{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project work \n",
    "## Balogh Nóra, Gyulai László, Vargha Noémi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we have implemented 2 dimensional Ising model with Monte-Carlo simulation. We aimed to train neural networks based on the simulation results. \n",
    "The main parts of our work:\n",
    "1. Implementing Monte-Carlo simulation code for the Ising model\n",
    "2. Generating training data\n",
    "3. Neural Network learns to calculate energy and magnetization\n",
    "4. Neural Network learns to calculate coupling strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qv6ca0WfX6H"
   },
   "source": [
    "Ideas:\n",
    "\n",
    "https://arxiv.org/pdf/1706.09779.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoBa55hQJTpt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTl2-2RKSfm6"
   },
   "source": [
    "# 1. Monte-Carlo simulation code for the Ising model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2d2NEVtSmEW"
   },
   "source": [
    "We used a square lattice od size LxL=10x10. Each cell in the square lattice has spin $\\sigma_i=\\pm 1$ which is initialized randomly. The Hamiltonian of the system is:\n",
    "\n",
    "$$ H=-K\\sum_{\\langle i\\mathrm{,}j \\rangle} \\sigma_i \\sigma_J - h\\sum_{i}\\sigma_i$$\n",
    "where the summation runs over the nearest neighbors, $K$ is coupling strength between the nearest neighbors and $h$ is the external field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFT3jjyDStN_"
   },
   "source": [
    "assiged each lattice cell a random spin of $\\pm 1$ with the function below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0O5SC8tJRMZ"
   },
   "source": [
    "Parameters of the 2D Ising model: \n",
    "* hi: interaction with external field\n",
    "* Kij: interactions between neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28fAGGEnKJat"
   },
   "outputs": [],
   "source": [
    "def initialize(L):   \n",
    "    ''' generates a random spin (+1 or -1) configuration for initial condition'''\n",
    "    state = 2*np.random.randint(2, size=(L,L))-1\n",
    "    return state #square lattice, cells filled randomly with +1 or -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdGrBwzFSyfc"
   },
   "source": [
    "Magnetization is the average value of the spin. (Source: https://en.wikipedia.org/wiki/Ising_model). The energy of a configuration is calculated from the Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjFP3RE7SVH4"
   },
   "outputs": [],
   "source": [
    "def magnetization(config):\n",
    "    '''Magnetization of a given configuration'''\n",
    "    mag = np.sum(config)/(config.shape[0]*config.shape[1])\n",
    "    return mag\n",
    "\n",
    "def Energy(config, h, K):\n",
    "    '''Calculates energy of a given configuration'''\n",
    "    energy = 0\n",
    "    L=len(config)\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            S = config[i,j]\n",
    "            energy-=h*S\n",
    "            #neighbors with periodic boundary conditions\n",
    "            neighbors = config[(i+1)%L, j] + config[i,(j+1)%L] + config[(i-1)%L, j] + config[i,(j-1)%L] \n",
    "            energy -= K*neighbors*S\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTBgIHiUS32d"
   },
   "source": [
    "One Monte Carlo timestep consists of LxL elementary step in which a spin is chosen randomly and flipped according to the Metropolis probabilities. \n",
    "\n",
    "In each elementary step we randomly choose a lattice point with spin $s$. If the spin is flipped, the cost is $\\Delta E=E_{flipped}-E_{original}$. From the Hamiltonian:\n",
    "\n",
    "$$\\Delta E= 2hs-2Ks\\cdot nb$$\n",
    "\n",
    "where $nb$ is the sum of the spins of the nearest neighbors of s. The function \"mcmove\" below calculates this cost and flips the spin if $\\Delta E < 0$ and flips this spin with probability $p=\\exp(\\beta\\cdot\\Delta E)$ if $E>0$. ($\\beta=\\frac{1}{k_bT}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHj-h6pISXv9"
   },
   "outputs": [],
   "source": [
    "def mcmove(config, beta, h, K):\n",
    "    '''Monte Carlo move using Metropolis algorithm '''\n",
    "    L=len(config)\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "                a = np.random.randint(0, L)\n",
    "                b = np.random.randint(0, L)\n",
    "                s =  config[a, b]\n",
    "                neighbors = config[(a+1)%L,b] + config[a,(b+1)%L] + config[(a-1)%L,b] + config[a,(b-1)%L]\n",
    "                #cost=difference between energies\n",
    "                cost = 2*h*s + 2*K*neighbors*s\n",
    "                if cost < 0:\n",
    "                    s *= -1\n",
    "                elif np.random.rand() < np.exp(-cost*beta):\n",
    "                    s *= -1\n",
    "                config[a, b] = s\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ks2guv5cTBx1"
   },
   "source": [
    "Use Monte carlo step as: config=mcmove(config, beta, h, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdXA43BDTjlZ"
   },
   "source": [
    "# 2. Training data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generation of lattices for energy and magnetization prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "W6Jwrf4HVCq3",
    "outputId": "a5b3d795-ac88-45f8-da39-9ae019e7ce12"
   },
   "outputs": [],
   "source": [
    "K=1\n",
    "beta=0.2\n",
    "L=10\n",
    "h=5\n",
    "timesteps = 500\n",
    "iterations = 20\n",
    "config_data=[]\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    config=initialize(L)\n",
    "    E,M=np.zeros(timesteps), np.zeros(timesteps)\n",
    "    M0=np.zeros(timesteps)\n",
    "    for t in range(timesteps):\n",
    "        E[t]=Energy(config, h, K)\n",
    "        M[t]=magnetization(config)\n",
    "        row1 = [E[t]]+[M[t]]+list(config.flatten())\n",
    "        config_data.append(row1)\n",
    "        config=mcmove(config, beta, h, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store in a .csv file the following features of each generated lattice:\n",
    "* energy\n",
    "* magnetization\n",
    "* config: the lattice configuration (array of +1, -1 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "k5iEJOKFVVu-",
    "outputId": "0f2d04eb-20ab-42df-8d6c-5194c86e8a90"
   },
   "outputs": [],
   "source": [
    "with open('training_data.csv', 'w+', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(config_data)\n",
    "writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Training data generation for coupling strength prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration we use different coupling strength and step 10 Monte-Carlo steps (timesteps) with it. Temperature and external field values are fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=1\n",
    "beta=0.2\n",
    "L=10\n",
    "h=5\n",
    "timesteps = 10\n",
    "iterations = 5000\n",
    "config_data=[]\n",
    "\n",
    "E,M=np.zeros(iterations), np.zeros(iterations)\n",
    "#Klist=[j/1000 for j in range(iterations)]\n",
    "for i in range(iterations):\n",
    "    K=np.random.normal()+1  # k is a random value between 0 and 2\n",
    "    config=initialize(L)\n",
    "    for t in range(timesteps):\n",
    "        config=mcmove(config, beta, h, K)\n",
    "    E[i]=Energy(config, h, K)\n",
    "    M[i]=magnetization(config)\n",
    "    row1 = [K]+[E[i]]+[M[i]]+list(config.flatten())\n",
    "    config_data.append(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data2.csv', 'w+', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(config_data)\n",
    "writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Network learns to calculate energy and magnetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"training_data.csv\", names=[\"E\"]+[\"M\"]+[i for i in range(L*L)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabelsE=traindata[\"E\"].values\n",
    "trainlabelsM=traindata[\"M\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attrs=traindata.drop(columns=[\"E\", \"M\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Magnetization prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(trainlabelsM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trainlabelsM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04,  0.44,  0.72, ...,  0.92,  0.96,  0.92])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlabelsM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainlabelsM=(trainlabelsM-(-1))/(1-(-1))\n",
    "trainlabelsM=(trainlabelsM-min(trainlabelsM))/(max(trainlabelsM)-min(trainlabelsM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(train_attrs, trainlabelsM, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6700, 100), (6700,), (3300, 100), (3300,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=100, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,201\n",
      "Trainable params: 10,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/100\n",
      "6700/6700 [==============================] - 0s 43us/step - loss: 0.0463 - val_loss: 0.0083\n",
      "Epoch 2/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 4/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 7.8930e-04 - val_loss: 8.3094e-04\n",
      "Epoch 5/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 5.0175e-04 - val_loss: 6.3748e-04\n",
      "Epoch 6/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 3.5736e-04 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 2.9739e-04 - val_loss: 5.2830e-04\n",
      "Epoch 8/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.0750e-04 - val_loss: 8.8820e-04\n",
      "Epoch 9/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.2129e-04 - val_loss: 3.5737e-04\n",
      "Epoch 10/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.7184e-04 - val_loss: 2.7840e-04\n",
      "Epoch 11/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.3572e-04 - val_loss: 3.6024e-04\n",
      "Epoch 12/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.4369e-04 - val_loss: 2.7300e-04\n",
      "Epoch 13/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.3496e-04 - val_loss: 2.7163e-04\n",
      "Epoch 14/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.9052e-04 - val_loss: 2.6775e-04\n",
      "Epoch 15/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.4227e-04 - val_loss: 3.2567e-04\n",
      "Epoch 16/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.2727e-04 - val_loss: 2.9877e-04\n",
      "Epoch 17/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.5215e-04 - val_loss: 3.4135e-04\n",
      "Epoch 18/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.8019e-04 - val_loss: 3.7209e-04\n",
      "Epoch 19/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.1938e-04 - val_loss: 9.5445e-04\n",
      "Epoch 20/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 4.5812e-04 - val_loss: 0.0035\n",
      "Epoch 21/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 4.5160e-04 - val_loss: 0.0010\n",
      "Epoch 22/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.8592e-04 - val_loss: 7.8077e-04\n",
      "Epoch 23/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 3.2499e-04 - val_loss: 2.8076e-04\n",
      "Epoch 24/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.8243e-04 - val_loss: 2.0966e-04\n",
      "Epoch 25/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.9117e-04 - val_loss: 2.1833e-04\n",
      "Epoch 26/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.4516e-04 - val_loss: 1.3320e-04\n",
      "Epoch 27/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.9525e-04 - val_loss: 1.2842e-04\n",
      "Epoch 28/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.7944e-04 - val_loss: 5.5456e-04\n",
      "Epoch 29/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.9831e-04 - val_loss: 1.2281e-04\n",
      "Epoch 30/100\n",
      "6700/6700 [==============================] - 0s 26us/step - loss: 3.0323e-04 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 6.8180e-04 - val_loss: 1.0396e-04\n",
      "Epoch 32/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.7372e-04 - val_loss: 1.1056e-04\n",
      "Epoch 33/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.4584e-04 - val_loss: 8.8586e-05\n",
      "Epoch 34/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.5432e-04 - val_loss: 2.1574e-04\n",
      "Epoch 35/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.9761e-04 - val_loss: 3.1065e-04\n",
      "Epoch 36/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.8416e-04 - val_loss: 8.4911e-05\n",
      "Epoch 37/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.8578e-04 - val_loss: 1.6141e-04\n",
      "Epoch 38/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.8653e-04 - val_loss: 1.0694e-04\n",
      "Epoch 39/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.6468e-04 - val_loss: 8.9866e-05\n",
      "Epoch 40/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.0375e-04 - val_loss: 2.1837e-04\n",
      "Epoch 41/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.6581e-04 - val_loss: 8.2248e-05\n",
      "Epoch 42/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.1573e-04 - val_loss: 3.7585e-04\n",
      "Epoch 43/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.4919e-04 - val_loss: 8.1330e-05\n",
      "Epoch 44/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 2.3774e-04 - val_loss: 4.7765e-04\n",
      "Epoch 45/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 2.0250e-04 - val_loss: 1.1913e-04\n",
      "Epoch 46/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.4944e-04 - val_loss: 6.2397e-04\n",
      "Epoch 47/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 9.1264e-04 - val_loss: 7.4391e-05\n",
      "Epoch 48/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.0002e-04 - val_loss: 9.8653e-05\n",
      "Epoch 49/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 9.7960e-05 - val_loss: 8.2893e-05\n",
      "Epoch 50/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.0362e-04 - val_loss: 7.7520e-05\n",
      "Epoch 51/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.1123e-04 - val_loss: 2.7200e-04\n",
      "Epoch 52/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.6272e-04 - val_loss: 7.5300e-05\n",
      "Epoch 53/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.6597e-04 - val_loss: 8.5988e-05\n",
      "Epoch 54/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.6370e-04 - val_loss: 7.7600e-05\n",
      "Epoch 55/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.6647e-04 - val_loss: 1.3906e-04\n",
      "Epoch 56/100\n",
      "6700/6700 [==============================] - 0s 25us/step - loss: 1.8304e-04 - val_loss: 2.1045e-04\n",
      "Epoch 57/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.7962e-04 - val_loss: 1.5767e-04\n",
      "Epoch 58/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.4457e-04 - val_loss: 7.4169e-05\n",
      "Epoch 59/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.6310e-04 - val_loss: 1.3674e-04\n",
      "Epoch 60/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.8363e-04 - val_loss: 1.8015e-04\n",
      "Epoch 61/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.8325e-04 - val_loss: 1.3435e-04\n",
      "Epoch 62/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.5545e-04 - val_loss: 1.3860e-04\n",
      "Epoch 63/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.1472e-04 - val_loss: 1.2414e-04\n",
      "Epoch 64/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.5042e-04 - val_loss: 7.2797e-05\n",
      "Epoch 65/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.4844e-04 - val_loss: 1.9304e-04\n",
      "Epoch 66/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.6275e-04 - val_loss: 6.9435e-05\n",
      "Epoch 67/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.4293e-04 - val_loss: 1.7793e-04\n",
      "Epoch 68/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3565e-04 - val_loss: 7.3113e-05\n",
      "Epoch 69/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.6522e-04 - val_loss: 1.0222e-04\n",
      "Epoch 70/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.8436e-04 - val_loss: 6.0167e-05\n",
      "Epoch 71/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.1472e-04 - val_loss: 6.3931e-05\n",
      "Epoch 72/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.9015e-04 - val_loss: 1.4502e-04\n",
      "Epoch 73/100\n",
      "6700/6700 [==============================] - 0s 25us/step - loss: 1.1350e-04 - val_loss: 5.6661e-05\n",
      "Epoch 74/100\n",
      "6700/6700 [==============================] - 0s 25us/step - loss: 1.2967e-04 - val_loss: 1.1325e-04\n",
      "Epoch 75/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.3005e-04 - val_loss: 3.5763e-04\n",
      "Epoch 76/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.9418e-04 - val_loss: 6.2119e-05\n",
      "Epoch 77/100\n",
      "6700/6700 [==============================] - 0s 20us/step - loss: 1.1604e-04 - val_loss: 5.2118e-04\n",
      "Epoch 78/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.4130e-04 - val_loss: 6.4923e-05\n",
      "Epoch 79/100\n",
      "6700/6700 [==============================] - 0s 24us/step - loss: 1.5197e-04 - val_loss: 1.6206e-04\n",
      "Epoch 80/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.8274e-04 - val_loss: 1.6595e-04\n",
      "Epoch 81/100\n",
      "6700/6700 [==============================] - 0s 25us/step - loss: 1.0378e-04 - val_loss: 6.4206e-05\n",
      "Epoch 82/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.3996e-04 - val_loss: 1.1748e-04\n",
      "Epoch 83/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.6299e-04 - val_loss: 1.1567e-04\n",
      "Epoch 84/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.1758e-04 - val_loss: 9.3142e-05\n",
      "Epoch 85/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.5212e-04 - val_loss: 6.7238e-05\n",
      "Epoch 86/100\n",
      "6700/6700 [==============================] - 0s 24us/step - loss: 1.2903e-04 - val_loss: 8.1630e-05\n",
      "Epoch 87/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.4384e-04 - val_loss: 5.5154e-05\n",
      "Epoch 88/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.2623e-04 - val_loss: 1.6352e-04\n",
      "Epoch 89/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.2890e-04 - val_loss: 6.9255e-05\n",
      "Epoch 90/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3332e-04 - val_loss: 9.3086e-05\n",
      "Epoch 91/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.7272e-04 - val_loss: 5.8617e-05\n",
      "Epoch 92/100\n",
      "6700/6700 [==============================] - 0s 22us/step - loss: 1.0922e-04 - val_loss: 1.0116e-04\n",
      "Epoch 93/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3937e-04 - val_loss: 7.9088e-05\n",
      "Epoch 94/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.4913e-04 - val_loss: 4.3698e-04\n",
      "Epoch 95/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3673e-04 - val_loss: 9.0687e-05\n",
      "Epoch 96/100\n",
      "6700/6700 [==============================] - 0s 24us/step - loss: 1.1646e-04 - val_loss: 6.7394e-05\n",
      "Epoch 97/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3907e-04 - val_loss: 6.4052e-05\n",
      "Epoch 98/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.2415e-04 - val_loss: 2.2615e-04\n",
      "Epoch 99/100\n",
      "6700/6700 [==============================] - 0s 23us/step - loss: 1.3774e-04 - val_loss: 6.1892e-05\n",
      "Epoch 100/100\n",
      "6700/6700 [==============================] - 0s 21us/step - loss: 1.3721e-04 - val_loss: 3.0640e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=Y_train, batch_size=32, epochs=100, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.0003063977349365151\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print('MSE : ', mean_squared_error(preds, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "Y_hist = plt.hist(Y_test, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='r')\n",
    "plt.title(\"Y_test\")\n",
    "pred_hist = plt.hist(preds, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='b')\n",
    "plt.legend([\"real labels\", \"estimated\"], loc='upper left')\n",
    "plt.xlabel(\"magnetization\", fontsize = 14)\n",
    "plt.ylabel(\"count\",  fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Energy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(trainlabelsE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-900.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trainlabelsE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabelsE=(trainlabelsE-min(trainlabelsE))/(max(trainlabelsE)-min(trainlabelsE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trainlabelsE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainE, X_testE, Y_trainE, Y_testE = train_test_split(train_attrs, trainlabelsE, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=100, activation='relu'))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dense(30, activation='relu'))\n",
    "model2.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 16,711\n",
      "Trainable params: 16,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/100\n",
      "6700/6700 [==============================] - 0s 46us/step - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 2/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 3/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 4/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 0.0026 - val_loss: 9.0791e-04\n",
      "Epoch 5/100\n",
      "6700/6700 [==============================] - 0s 16us/step - loss: 7.2906e-04 - val_loss: 6.6341e-04\n",
      "Epoch 6/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 5.1134e-04 - val_loss: 6.1371e-04\n",
      "Epoch 7/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.7253e-04 - val_loss: 4.8657e-04\n",
      "Epoch 8/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 3.2988e-04 - val_loss: 4.3452e-04\n",
      "Epoch 9/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 3.0934e-04 - val_loss: 4.2270e-04\n",
      "Epoch 10/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 2.5403e-04 - val_loss: 4.6692e-04\n",
      "Epoch 11/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 2.5111e-04 - val_loss: 3.8298e-04\n",
      "Epoch 12/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.3678e-04 - val_loss: 3.5835e-04\n",
      "Epoch 13/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.5118e-04 - val_loss: 3.5113e-04\n",
      "Epoch 14/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 2.3888e-04 - val_loss: 3.3910e-04\n",
      "Epoch 15/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 2.1836e-04 - val_loss: 3.9200e-04\n",
      "Epoch 16/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 2.2053e-04 - val_loss: 3.2168e-04\n",
      "Epoch 17/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.0928e-04 - val_loss: 3.0969e-04\n",
      "Epoch 18/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.8621e-04 - val_loss: 2.9223e-04\n",
      "Epoch 19/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.7350e-04 - val_loss: 3.2263e-04\n",
      "Epoch 20/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 1.7778e-04 - val_loss: 2.6235e-04\n",
      "Epoch 21/100\n",
      "6700/6700 [==============================] - 0s 16us/step - loss: 1.6923e-04 - val_loss: 3.0144e-04\n",
      "Epoch 22/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.0779e-04 - val_loss: 2.7780e-04\n",
      "Epoch 23/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.0759e-04 - val_loss: 3.7397e-04\n",
      "Epoch 24/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.0104e-04 - val_loss: 2.4348e-04\n",
      "Epoch 25/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.4547e-04 - val_loss: 2.6907e-04\n",
      "Epoch 26/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.4899e-04 - val_loss: 4.1676e-04\n",
      "Epoch 27/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.6044e-04 - val_loss: 2.8890e-04\n",
      "Epoch 28/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.6294e-04 - val_loss: 3.2142e-04\n",
      "Epoch 29/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.1283e-04 - val_loss: 3.5773e-04\n",
      "Epoch 30/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.1528e-04 - val_loss: 2.8416e-04\n",
      "Epoch 31/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.8784e-04 - val_loss: 3.2071e-04\n",
      "Epoch 32/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.7837e-04 - val_loss: 2.8808e-04\n",
      "Epoch 33/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.8815e-04 - val_loss: 2.7028e-04\n",
      "Epoch 34/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 1.6249e-04 - val_loss: 2.2668e-04\n",
      "Epoch 35/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.4013e-04 - val_loss: 2.1050e-04\n",
      "Epoch 36/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.6698e-04 - val_loss: 2.2421e-04\n",
      "Epoch 37/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.6054e-04 - val_loss: 2.7347e-04\n",
      "Epoch 38/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.1196e-04 - val_loss: 2.5605e-04\n",
      "Epoch 39/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.0148e-04 - val_loss: 2.6875e-04\n",
      "Epoch 40/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.2641e-04 - val_loss: 2.4072e-04\n",
      "Epoch 41/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.1043e-04 - val_loss: 2.4538e-04\n",
      "Epoch 42/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 8.5789e-05 - val_loss: 2.0870e-04\n",
      "Epoch 43/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 7.9371e-05 - val_loss: 2.3521e-04\n",
      "Epoch 44/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 9.8144e-05 - val_loss: 2.4827e-04\n",
      "Epoch 45/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 6.4969e-05 - val_loss: 2.4456e-04\n",
      "Epoch 46/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 8.8783e-05 - val_loss: 2.4241e-04\n",
      "Epoch 47/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 9.5675e-05 - val_loss: 2.8629e-04\n",
      "Epoch 48/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 9.2001e-05 - val_loss: 2.5288e-04\n",
      "Epoch 49/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.3692e-04 - val_loss: 2.8992e-04\n",
      "Epoch 50/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.3048e-04 - val_loss: 2.3019e-04\n",
      "Epoch 51/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 1.2334e-04 - val_loss: 2.0251e-04\n",
      "Epoch 52/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 1.2470e-04 - val_loss: 2.4465e-04\n",
      "Epoch 53/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 8.6297e-05 - val_loss: 1.8108e-04\n",
      "Epoch 54/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.0387e-04 - val_loss: 1.7673e-04\n",
      "Epoch 55/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.3145e-04 - val_loss: 2.2125e-04\n",
      "Epoch 56/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 9.8194e-05 - val_loss: 2.1349e-04\n",
      "Epoch 57/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 8.7307e-05 - val_loss: 2.1779e-04\n",
      "Epoch 58/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 8.1872e-05 - val_loss: 2.3609e-04\n",
      "Epoch 59/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 6.5726e-05 - val_loss: 2.0276e-04\n",
      "Epoch 60/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 7.5456e-05 - val_loss: 2.0403e-04\n",
      "Epoch 61/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 6.1114e-05 - val_loss: 2.2222e-04\n",
      "Epoch 62/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 5.4757e-05 - val_loss: 1.6872e-04\n",
      "Epoch 63/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 5.9361e-05 - val_loss: 2.5263e-04\n",
      "Epoch 64/100\n",
      "6700/6700 [==============================] - ETA: 0s - loss: 4.6570e-0 - 0s 15us/step - loss: 5.3771e-05 - val_loss: 1.8171e-04\n",
      "Epoch 65/100\n",
      "6700/6700 [==============================] - 0s 17us/step - loss: 5.6788e-05 - val_loss: 3.0584e-04\n",
      "Epoch 66/100\n",
      "6700/6700 [==============================] - 0s 16us/step - loss: 6.5091e-05 - val_loss: 1.4948e-04\n",
      "Epoch 67/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 5.7455e-05 - val_loss: 1.6258e-04\n",
      "Epoch 68/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 6.9598e-05 - val_loss: 2.0332e-04\n",
      "Epoch 69/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 6.8590e-05 - val_loss: 2.0118e-04\n",
      "Epoch 70/100\n",
      "6700/6700 [==============================] - 0s 18us/step - loss: 7.0734e-05 - val_loss: 2.3669e-04\n",
      "Epoch 71/100\n",
      "6700/6700 [==============================] - 0s 16us/step - loss: 1.1239e-04 - val_loss: 1.6155e-04\n",
      "Epoch 72/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 6.8656e-05 - val_loss: 1.6386e-04\n",
      "Epoch 73/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 6.5449e-05 - val_loss: 1.6285e-04\n",
      "Epoch 74/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 1.2916e-04 - val_loss: 1.5346e-04\n",
      "Epoch 75/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.4664e-04 - val_loss: 2.6980e-04\n",
      "Epoch 76/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.3508e-04 - val_loss: 1.6402e-04\n",
      "Epoch 77/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 6.2690e-05 - val_loss: 1.5513e-04\n",
      "Epoch 78/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.4216e-05 - val_loss: 1.3988e-04\n",
      "Epoch 79/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.4806e-05 - val_loss: 1.4517e-04\n",
      "Epoch 80/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.2969e-05 - val_loss: 1.3328e-04\n",
      "Epoch 81/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 4.0551e-05 - val_loss: 2.0161e-04\n",
      "Epoch 82/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.0087e-05 - val_loss: 1.3500e-04\n",
      "Epoch 83/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.7657e-05 - val_loss: 1.2472e-04\n",
      "Epoch 84/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.9260e-05 - val_loss: 1.4157e-04\n",
      "Epoch 85/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.8124e-05 - val_loss: 1.2345e-04\n",
      "Epoch 86/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.0886e-05 - val_loss: 1.2925e-04\n",
      "Epoch 87/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.7691e-05 - val_loss: 1.4433e-04\n",
      "Epoch 88/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.6137e-05 - val_loss: 1.4279e-04\n",
      "Epoch 89/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.6925e-05 - val_loss: 1.2765e-04\n",
      "Epoch 90/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.1655e-05 - val_loss: 1.3989e-04\n",
      "Epoch 91/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 3.5668e-05 - val_loss: 1.1718e-04\n",
      "Epoch 92/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 5.4470e-05 - val_loss: 1.4867e-04\n",
      "Epoch 93/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 5.4770e-05 - val_loss: 1.3947e-04\n",
      "Epoch 94/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 7.8101e-05 - val_loss: 1.2246e-04\n",
      "Epoch 95/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 7.8687e-05 - val_loss: 1.4130e-04\n",
      "Epoch 96/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 1.0096e-04 - val_loss: 1.1429e-04\n",
      "Epoch 97/100\n",
      "6700/6700 [==============================] - 0s 15us/step - loss: 5.1945e-05 - val_loss: 1.2295e-04\n",
      "Epoch 98/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 4.3305e-05 - val_loss: 1.1678e-04\n",
      "Epoch 99/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.7169e-05 - val_loss: 1.1534e-04\n",
      "Epoch 100/100\n",
      "6700/6700 [==============================] - 0s 14us/step - loss: 2.1146e-05 - val_loss: 1.1049e-04\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(x=X_trainE, y=Y_trainE, batch_size=64, epochs=100, validation_data=(X_testE, Y_testE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.0001104853180888348\n"
     ]
    }
   ],
   "source": [
    "predsE = model2.predict(X_testE)\n",
    "print('MSE : ', mean_squared_error(predsE, Y_testE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "Y_hist = plt.hist(Y_testE, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='r')\n",
    "plt.title(\"Y_test\")\n",
    "pred_hist = plt.hist(predsE, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='b')\n",
    "plt.legend([\"real labels\", \"estimated\"], loc='upper right')\n",
    "plt.xlabel(\"energy\", fontsize = 14)\n",
    "plt.ylabel(\"count\",  fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Network learns to calculate coupling strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata2 = pd.read_csv(\"training_data2.csv\", names=[\"K\"]+[\"E\"]+[\"M\"]+[i for i in range(L*L)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>E</th>\n",
       "      <th>M</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981545</td>\n",
       "      <td>-866.913386</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244548</td>\n",
       "      <td>-472.604335</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.479373</td>\n",
       "      <td>-1058.079211</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.178758</td>\n",
       "      <td>-1649.783027</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148842</td>\n",
       "      <td>-438.103564</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          K            E     M  0  1  2  3  4  5  6 ...  90  91  92  93  94  \\\n",
       "0  0.981545  -866.913386  0.98  1  1  1  1  1  1  1 ...   1   1   1   1   1   \n",
       "1  0.244548  -472.604335  0.82  1  1  1  1  1  1  1 ...   1   1   1   1   1   \n",
       "2  1.479373 -1058.079211  0.98  1  1  1  1  1  1  1 ...   1   1   1   1   1   \n",
       "3  3.178758 -1649.783027  0.96  1  1  1 -1  1  1  1 ...   1   1   1   1   1   \n",
       "4  0.148842  -438.103564  0.80  1  1  1  1  1  1  1 ...   1   1   1   1   1   \n",
       "\n",
       "   95  96  97  98  99  \n",
       "0   1   1   1   1   1  \n",
       "1   1   1   1   1   1  \n",
       "2   1   1   1   1   1  \n",
       "3   1   1   1   1   1  \n",
       "4   1  -1   1   1   1  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata2[\"E\"]=(traindata2[\"E\"]-min(traindata2[\"E\"]))/(max(traindata2[\"E\"])-min(traindata2[\"E\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata2[\"M\"]=(traindata2[\"M\"]-min(traindata2[\"M\"]))/(max(traindata2[\"M\"])-min(traindata2[\"M\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabelsK=traindata2[\"K\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attrs2=traindata2.drop(columns=[\"K\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabelsK=(trainlabelsK-min(trainlabelsK))/(max(trainlabelsK)-min(trainlabelsK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trainlabelsK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainK, X_testK, Y_trainK, Y_testK = train_test_split(train_attrs2, trainlabelsK, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3350, 102), (3350,), (1650, 102), (1650,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainK.shape, Y_trainK.shape, X_testK.shape, Y_testK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(102, input_dim=102, activation='relu'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(40, activation='relu'))\n",
    "model3.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 102)               10506     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10300     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                4040      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 34,987\n",
      "Trainable params: 34,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3350 samples, validate on 1650 samples\n",
      "Epoch 1/100\n",
      "3350/3350 [==============================] - 0s 102us/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 4/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 5/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 6/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 9/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 10/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 11/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 12/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 14/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 8.7859e-04 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 7.5626e-04 - val_loss: 0.0024\n",
      "Epoch 16/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 7.2821e-04 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.5854e-04 - val_loss: 0.0022\n",
      "Epoch 18/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.8436e-04 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.9514e-04 - val_loss: 0.0021\n",
      "Epoch 20/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.7663e-04 - val_loss: 0.0025\n",
      "Epoch 21/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 4.6344e-04 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 4.9757e-04 - val_loss: 0.0033\n",
      "Epoch 23/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.0893e-04 - val_loss: 0.0021\n",
      "Epoch 24/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 3.1786e-04 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 3.8621e-04 - val_loss: 0.0020\n",
      "Epoch 26/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 3.1208e-04 - val_loss: 0.0029\n",
      "Epoch 27/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 4.6536e-04 - val_loss: 0.0023\n",
      "Epoch 28/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 5.7816e-04 - val_loss: 0.0020\n",
      "Epoch 29/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.7729e-04 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.8378e-04 - val_loss: 0.0019\n",
      "Epoch 31/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.7033e-04 - val_loss: 0.0018\n",
      "Epoch 32/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.0217e-04 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.7423e-04 - val_loss: 0.0019\n",
      "Epoch 34/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.9935e-04 - val_loss: 0.0019\n",
      "Epoch 35/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.8724e-04 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.1344e-04 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 1.4211e-04 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.3550e-04 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 3.8074e-04 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 4.3072e-04 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.6892e-04 - val_loss: 0.0023\n",
      "Epoch 42/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 3.5764e-04 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.5433e-04 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.2722e-04 - val_loss: 0.0017\n",
      "Epoch 45/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.2453e-04 - val_loss: 0.0017\n",
      "Epoch 46/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 8.1918e-05 - val_loss: 0.0020\n",
      "Epoch 47/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 8.7455e-05 - val_loss: 0.0017\n",
      "Epoch 48/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 8.7114e-05 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.3941e-04 - val_loss: 0.0017\n",
      "Epoch 50/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.1987e-04 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.1079e-04 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 4.2140e-04 - val_loss: 0.0019\n",
      "Epoch 53/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.6078e-04 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.8966e-04 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.1278e-04 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 8.1299e-05 - val_loss: 0.0017\n",
      "Epoch 57/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 2.0992e-04 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.4064e-04 - val_loss: 0.0019\n",
      "Epoch 59/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 2.2128e-04 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.3053e-04 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 3.5315e-04 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 2.2724e-04 - val_loss: 0.0018\n",
      "Epoch 63/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 2.6776e-04 - val_loss: 0.0017\n",
      "Epoch 64/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.5492e-04 - val_loss: 0.0018\n",
      "Epoch 65/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 2.4177e-04 - val_loss: 0.0025\n",
      "Epoch 66/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 2.6040e-04 - val_loss: 0.0017\n",
      "Epoch 67/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.3431e-04 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 8.9730e-05 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 7.0689e-05 - val_loss: 0.0016\n",
      "Epoch 70/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 7.1202e-05 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 8.7717e-05 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 7.6731e-05 - val_loss: 0.0016\n",
      "Epoch 73/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.0921e-04 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 6.8771e-05 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.3634e-04 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.4562e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 8.4579e-05 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 8.4325e-05 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 9.9866e-05 - val_loss: 0.0015\n",
      "Epoch 80/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 3.6033e-04 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 2.0272e-04 - val_loss: 0.0019\n",
      "Epoch 82/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 2.7051e-04 - val_loss: 0.0015\n",
      "Epoch 83/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 2.2900e-04 - val_loss: 0.0015\n",
      "Epoch 84/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 9.1139e-05 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 6.7970e-05 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.2413e-04 - val_loss: 0.0015\n",
      "Epoch 87/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.9477e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 7.0105e-05 - val_loss: 0.0014\n",
      "Epoch 89/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 8.1347e-05 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 7.0587e-05 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 6.6642e-05 - val_loss: 0.0014\n",
      "Epoch 92/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 7.6651e-05 - val_loss: 0.0015\n",
      "Epoch 93/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.9916e-04 - val_loss: 0.0014\n",
      "Epoch 94/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 7.7098e-05 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 8.0648e-05 - val_loss: 0.0014\n",
      "Epoch 96/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 8.8086e-05 - val_loss: 0.0015\n",
      "Epoch 97/100\n",
      "3350/3350 [==============================] - 0s 18us/step - loss: 1.4877e-04 - val_loss: 0.0019\n",
      "Epoch 98/100\n",
      "3350/3350 [==============================] - 0s 20us/step - loss: 1.8819e-04 - val_loss: 0.0015\n",
      "Epoch 99/100\n",
      "3350/3350 [==============================] - 0s 19us/step - loss: 1.7048e-04 - val_loss: 0.0015\n",
      "Epoch 100/100\n",
      "3350/3350 [==============================] - 0s 21us/step - loss: 1.1905e-04 - val_loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x=X_trainK, y=Y_trainK, batch_size=64, epochs=100, validation_data=(X_testK, Y_testK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.001403084344643398\n"
     ]
    }
   ],
   "source": [
    "predsK = model3.predict(X_testK)\n",
    "print('MSE : ', mean_squared_error(predsK, Y_testK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "Y_hist = plt.hist(Y_testK, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='r')\n",
    "plt.title(\"Y_test\")\n",
    "pred_hist = plt.hist(predsK, 50, (0,1.1),histtype=\"stepfilled\",alpha= 0.4, color ='b')\n",
    "plt.legend([\"real labels\", \"estimated\"], loc='upper right')\n",
    "plt.xlabel(\"coupling\", fontsize = 14)\n",
    "plt.ylabel(\"count\",  fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nagyhf_begin.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
